\section{Constructing \D: an Overview}

\subsection{Constructing the Standard Versions}

\D was designed as a package of useful subroutines rather than a
single program, which means that users are to be able to construct
a working simulation program of their own design from the
subroutines available, which is capable of performing a specific
simulation.  However, we recognise that many, perhaps most, users
will be content with creating a standard version that covers all
of the possible applications and for this reason we have only
provided the necessary tools to assemble such a version.  The
method of creating the standard version is described in detail in
this chapter, however a brief step-by-step description follows.

\begin{enumerate}
\item \D is supplied as a UNIX compressed file (tarred and
gzipped).  This must uncompressed and un-tared to create the \D
directory (Section \ref{directory-structure}).

\item In the {\em build} subdirectory you will find the required
\D makefiles (see Section \ref{compilation} and Appendix
\ref{makefiles}, where the main Makefiles are listed).  This must be
copied into the subdirectory containing the relevant source code. In
most cases this will be the {\em source} subdirectory.

\item The chosen makefile is executed with an appropriate keyword
(Section \ref{compilation}) which selects for specific platforms.
For \D compilation in parallel mode (a FORTRAN90 compiler
and an MPI implementation for the specific machine architecture are
required) in many cases the user (sometimes with help from the
administrator of their platform) will have to create their own
keyword entry in the makefile due to the large variety of (i)
software needed for the compilation of \D and (ii) places where
it could be installed (PATHS).  To facilitate the user with the
construction of their own keyword entry, examples are provided
in the makefiles.  In the case when users use a makefile for \D
compilation in serial mode they will have to provide a valid
PATH to the FORTRAN90 compiler on their specific platform.

\item The makefile produces the executable version of the code,
which as a default will be named DLPOLY.Z and located in the {\em
execute} subdirectory.

\item \D also has a Java GUI.  The files for this are stored
in the subdirectory {\em java}.  Compilation of this is simple and
requires running the javac compiler and the jar utility.  Details
for these procedures are provided in the GUI manual \cite{smith-gui}.

\item To run the executable for the first time you require the files
CONTROL, FIELD and CONFIG (and possibly TABLE - if you have
tabulated van der Walls potentials, TABEAM - if you have
tabulated metal potentials and REFERENCE - if defect detection is opted
for).  These must be present in the directory from which the program
is executed. (See Section \ref{input-files} for the description of
the input files.)

\item Executing the program will produce the files OUTPUT, STATIS,
REVCON and REVIVE (and optionally HISTORY, RDFDAT, ZDNDAT, MSDTMP,
REFERENCE, DEFECTS) in the executing directory.
(See Section \ref{output-files} for the description of the output files.)
\end{enumerate}

This simple procedure is enough to create a standard version to run
most simulations.  There may however be some difficulty with array
sizes.  \D contains features which allocate arrays after scanning
the input files for a simulation.  Sometimes these initial estimates
are insufficient for a long simulation when, for example, the system
volume changes markedly during the simulation or when a system is
artificially constructed to have a non-uniform density. Usually,
simply restarting the program will cure the problem, but sometimes,
especially when the local atom density is a way higher than the
global one or there is a sort of clustering in the system undergoes
and the distribution of bonded-like interactions is far from uniform,
it may be necessary to amend the array sizes in accordance with the
error message obtained.  A way to trigger lengthening of the density
dependent global arrays the user may use the {\bf densvar} option in
the CONTROL (Section \ref{control-file}) file.  However, lengthening
these array will require a larger amount of memory resources from the
execution machine for the simulation, which it may not be able to
provide.  See Section \ref{file-structure} for more insight on the
\D source code structure.

\subsection{Constructing Non-standard Versions}

In constructing a non-standard \D simulation program, the first
requirement is for the user to write a program to function as the
root segment.  The root segment {\sc /VV/dl\_poly} is placed in the
{\em source} directory and contains the set-up and close-down calls
for a molecular dynamics simulation.  It is the routine that first
opens the OUTPUT file (Section \ref{output-files}), which provides
the summary of the job.  The root program calls the ``molecular
dynamics cycle'' routines {\sc /LFV/md\_lfv} or {\sc /LFV/md\_vv}
implementing the VV and LFV depending on which integrator has been
specified for the simulation. These routines contain major routines
required to perform the simulation, control the normal ``molecular
dynamics cycle'' and monitor the {\em cpu} and {\em memory} usage.
They also bring about a controlled termination of the program; if
the {\em cpu} usage approaches the allotted job time within a
pre-set closure time and/or if the {\em memory} usage approaches the
allocated limit for density dependent arrays.   Users are
recommended to study the forementioned root drives as a model for
other implementations of the package they may wish to construct. The
dependencies and calling hierarchies of all the \D subroutines can
be found in the Section \ref{file-structure}.

Should additional functionality be added to \D by the user, the
{\sc set\_bounds} routine (and its support subroutines) may need
modifying to allow specification of the dimensions of any new
arrays.

Any molecular dynamics simulation performs five different kinds of
operation: initialisation; forces calculation; integration of the
equations of motion; calculation of system properties; and job
termination.  It is worth considering these operations in turn and
to indicate which \D routines are available to perform them.  We do
not give a detailed description, but provide only a guide.  Readers
are recommended to examine the different routines described in the
\D User Manual for further details (particularly regarding further
dependencies i.e. additional routines that may be called).

The following outline assumes a system containing flexible molecules
held together by rigid bonds.

Initialisation requires firstly that the program determine what
platform resources are made available to the specific simulation
job.  This is done by the \D routine {\sc map\_domains} in
{\sc domains\_module} that attempts to allocate and map the
resources (nodes in parallel) in compliance with the DD
strategy\index{parallelisation}.  {\sc map\_domains}, is called
within the routine {\sc set\_bounds}, which also sets the necessary
limits for various simulation array sizes and all global
variables as declared in {\sc setup\_module} to convenient values
based on rough scan through the CONFIG, CONTROL, FIELD and optionally
TABLE and TABEAM (Section \ref{input-files}) files.  The routine also
calls the {\sc read\_config} routine to obtain atomic positions and
optionally velocities and forces the CONFIG file.  After allocation
of all necessary simulation arrays and variables (with compulsory
initialisation to "zero" value), the job control information is
required; this is obtained by the routine {\sc read\_control}, which
reads the CONTROL file.  The description of the system to be
simulated: the types of atoms and molecules present and the
intermolecular forces, are obtained by the {\sc read\_field} routine,
which reads the FIELD file.  The {\sc system\_init} routine is
called next to initialise various simulation arrays and variables
intact with the data so far and detects if the job is a restart of
previous simulation run.  If so it reads the REVOLD (Section
\ref{revold-file}) to supply some arrays and variables with the
necessary values as saved from the previous job.  The domain halo is
constructed strait after by the routine {\sc set\_halo\_particles}.
After gathering all these data, bookkeeping and exclusion arrays are
created for the intramolecular and site related interactions
(core\_shell, constraint and tether units) by {\sc build\_book\_intra}
and {\sc build\_excl\_intra} routines.  Lastly, the thermodynamic
properties of the system are checked and set intact by the
{\sc set\_temperature} routine (which also generates the initial
velocities if required to do so).

The calculation of the pair-like forces is carried out in the
{\sc two\_body\_forces} routine and represents the main part of any
simulation.  For calculation of the two-body contributions to the
atomic forces, the Verlet neighbour list\index{Verlet neighbour list}
is constructed by {\sc link\_cell\_pairs} routine using link-cell
lists.  Special measures are taken so that the lsit excludes: (i)
pairs of atoms that are both in {\em frozen state} as well as (ii)
pairs in which one of the atoms has the other in its
{\em exclusion list}.  The last is build by {\sc build\_excl\_intra}
where the specification of bonded-like interactions in the FIELD file
are processed.  Various other subroutines are then called to
calculate specific contributions by different interactions.  For example;
{\sc vdw\_forces} for the short-range (van der Waals\index{potential!van der Waals})
forces (Section \ref{vdw}), {\sc metal\_lrc}, {\sc metal\_ld\_compute} and
{\sc metal\_forces} for the metal interactions \index{potential!metal}
(Section \ref{metal}), and {\sc ewald\_spme\_forces}, {\sc ewald\_real\_forces},
{\sc ewald\_frozen\_forces} and {\sc ewald\_excl\_forces} for the
Coulombic forces (Section \ref{coulomb}).

Higher order intermolecular\index{potential!intermolecular}, site
related and intramolecular\index{potential!intramolecular} forces
require the routines; \\
{\sc tersoff\_forces}, {\sc three\_body\_forces},
{\sc four\_body\_forces}, \\
{\sc core\_shell\_forces} or {\sc core\_shell\_relax},
{\sc tethers\_forces}, \\
{\sc bonds\_forces}, {\sc angles\_forces}, {\sc dihedrals\_forces}
and {\sc inversions\_forces}.  \\
The routines; \\
{\sc external\_field\_apply} and {\sc external\_field\_correct},
are required if the simulated system has an external force field
(e.g. electrostatic field) operating.

To help with equilibration simulations, routines such as
{\sc cap\_forces}, {\sc zero\_k\_optimise} and {\sc minimise\_relax}
are sometimes required to reduce the magnitude of badly
equilibrated forces and to steer the MD system towards an
equlibrium state.

Integration of the equations of motion is handled by one of the
routines listed and described in Chapter \ref{integration-algorithms}.

As mentioned elsewhere, \D does not contain many routines for
computing system properties during a simulation.  Radial
distributions may be calculated however, by using the routines
{\sc rdf\_collect}, {\sc rdf\_excl\_collect} and {\sc rdf\_compute}.
Similarly, Z-density distribution may be calculated by using the
routines {\sc z\_density\_collect} and {\sc z\_density\_compute}.
Ordinary thermodynamic quantities are calculated by the routine
{\sc statistics\_collect}, which also writes the STATIS file (Section
\ref{statis-file}).  Routine {\sc trajectory\_write} writes the
HISTORY (Section \ref{history-file}) file for later (postmortem)
analysis.  Routine {\sc defects\_write} writes the DEFECTS (Section
\ref{defects-file}) file for later (postmortem) analysis.  Routine
{\sc msd\_write} writes the MSDTMP (Section \ref{msdtmp-file})
file for later (postmortem) analysis.  Routine {\sc rsd\_write}
writes the RSDDAT (Section \ref{rsddat-file}) file for later
(postmortem) analysis.

Job termination is handled by the routine {\sc statistics\_result}
which writes the final summaries in the OUTPUT file and dumps the
restart files REVIVE and REVCON (Sections \ref{revive-file} and
\ref{revcon-file} respectively).
